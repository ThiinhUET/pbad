{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T13:51:26.085666Z",
     "start_time": "2019-04-25T13:51:25.233680Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing PBAD and PreProcessor requires that the Cython code is compiled (using setup.py).\n",
    "\n",
    "The path from where they are imported can differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T13:51:26.140061Z",
     "start_time": "2019-04-25T13:51:26.110810Z"
    }
   },
   "outputs": [],
   "source": [
    "# try loading the relevant methods\n",
    "try:\n",
    "    cwd = os.getcwd()\n",
    "    src_path = os.path.join(cwd.split('notebooks')[0], 'src')\n",
    "    sys.path.insert(0, src_path)\n",
    "except:\n",
    "    print('Failed to add path')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T13:51:33.733368Z",
     "start_time": "2019-04-25T13:51:33.617192Z"
    }
   },
   "outputs": [],
   "source": [
    "from methods.PreProcessor import PreProcessor\n",
    "from methods.PBAD import PBAD\n",
    "from baselines.PAV import PAV\n",
    "from baselines.FPOF import FPOF\n",
    "from baselines.MPAD import MPAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T13:51:40.490694Z",
     "start_time": "2019-04-25T13:51:40.462493Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(cwd.split('notebooks')[0], 'data/univariate')\n",
    "univariate_data = pd.read_csv(os.path.join(data_path, 'ambient_temperature', 'train_data.csv'), index_col=0, header=0)\n",
    "continuous_data = {0: univariate_data.iloc[:, 0].values}\n",
    "labels = univariate_data.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T13:51:40.761248Z",
     "start_time": "2019-04-25T13:51:40.729373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alphabet_size': 30,\n",
       " 'bin_size': 1,\n",
       " 'capvalue': 0.5,\n",
       " 'data_type': 'univariate',\n",
       " 'discretize': False,\n",
       " 'dname': 'ambient_temperature',\n",
       " 'mph': 1,\n",
       " 'scaler': 1.0,\n",
       " 'scaling': False,\n",
       " 'wincrement': 6.0,\n",
       " 'wsize': 12.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read out the recommended preprocessing settings for this dataset (THIS STEP CAN BE SKIPPED)\n",
    "recommended_settings = pickle.load(open(os.path.join(data_path, 'ambient_temperature', 'data_settings.pickle'), 'rb'))\n",
    "recommended_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T14:55:41.362251Z",
     "start_time": "2019-04-25T14:55:41.205074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alphabet_size': 30,\n",
       " 'bin_size': 1,\n",
       " 'capvalue': 0.5,\n",
       " 'data_type': 'univariate',\n",
       " 'discretize': False,\n",
       " 'dname': 'request_latency',\n",
       " 'mph': 12,\n",
       " 'scaler': 1.0,\n",
       " 'scaling': False,\n",
       " 'wincrement': 6.0,\n",
       " 'wsize': 12.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read out the recommended preprocessing settings for this dataset (THIS STEP CAN BE SKIPPED)\n",
    "recommended_settings = pickle.load(open(os.path.join(data_path, 'request_latency', 'data_settings.pickle'), 'rb'))\n",
    "recommended_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T15:39:47.721114Z",
     "start_time": "2019-04-25T15:39:47.470790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alphabet_size': 30,\n",
       " 'bin_size': 1,\n",
       " 'capvalue': 0.5,\n",
       " 'data_type': 'univariate',\n",
       " 'discretize': False,\n",
       " 'dname': 'new_york_taxi',\n",
       " 'mph': 2,\n",
       " 'scaler': 1.0,\n",
       " 'scaling': False,\n",
       " 'wincrement': 6.0,\n",
       " 'wsize': 12.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read out the recommended preprocessing settings for this dataset (THIS STEP CAN BE SKIPPED)\n",
    "recommended_settings = pickle.load(open(os.path.join(data_path, 'new_york_taxi', 'data_settings.pickle'), 'rb'))\n",
    "recommended_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PBAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T09:57:36.593263Z",
     "start_time": "2019-04-25T09:56:54.166109Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running preprocessor on TIME SERIES with settings & steps:\n",
      "0. remove extreme values (mean +/- 3 * stdv) + min-max scaling is always applied FIRST\n",
      "1. scaling:             NO\n",
      "2. smoothing:           NO\n",
      "3. binning:             NO\n",
      "4. subsampling:         NO\n",
      "5. discretizing:        NO\n",
      "6. window (size - inc): 12 - 6\n",
      "WARNING: `anomaly_classifier` has no fit() function, using scikit-learn IsolationForest\n",
      "\n",
      "DEBUG: Mining CLOSED ITEMSETS with SPMF CHARM; #rows:1211 minsup absolute: 0.01\n",
      "\n",
      "DEBUG: Found #4509 patterns\n",
      "DEBUG: # Jaccard thresholded patterns: 4461\n",
      "DEBUG: most frequent patterns: [(array([ 0.55737921]), 285), (array([ 0.56866954]), 281), (array([ 0.60254055]), 271), (array([ 0.53479853]), 270), (array([ 0.59125022]), 269)]\n",
      "DEBUG: least frequent patterns: [(array([ 0.61383089,  0.62512123,  0.6477019 ,  0.68157291,  0.69286324]), 13), (array([ 0.61383089,  0.63641156,  0.6477019 ,  0.65899223,  0.67028257,\n",
      "        0.69286324]), 13), (array([ 0.50092753,  0.5235082 ,  0.53479853,  0.54608887,  0.55737921,\n",
      "        0.59125022]), 13), (array([ 0.60254055,  0.63641156,  0.65899223,  0.67028257,  0.69286324]), 13), (array([ 0.08318508]), 13)]\n",
      "\n",
      "DEBUG: Mining CLOSED SEQUENTIAL PATTERNS with CM-ClasP; #rows:1211 minsup absolute: 0.01\n",
      "\n",
      "DEBUG: Found #3628 patterns\n",
      "DEBUG: # Jaccard thresholded patterns: 1174\n",
      "DEBUG: most frequent patterns: [(array([ 0.43318551,  0.43318551]), 58), (array([ 0.37673383,  0.37673383]), 46), (array([ 0.17350777]), 44), (array([ 0.36544349,  0.36544349]), 44), (array([ 0.30899181,  0.32028214]), 44)]\n",
      "DEBUG: least frequent patterns: [(array([ 0.41060484,  0.3993145 ,  0.38802416]), 13), (array([ 0.65899223,  0.65899223,  0.70415358]), 13), (array([ 0.50092753,  0.45576618,  0.47834685]), 13), (array([ 0.47834685,  0.48963719,  0.55737921]), 13), (array([ 0.48963719,  0.51221786,  0.47834685]), 13)]\n",
      "PBAD - mining patterns + constructing features for continuous data took: 41.02640771865845 seconds\n",
      "PBAD - training classifier took: 0.8753674030303955 seconds\n"
     ]
    }
   ],
   "source": [
    "# preprocess the data\n",
    "prep = PreProcessor(scaling=False, smoothing=False, discretize=False, window_size=12, window_incr=6, bin_size=1, alphabet_size=30)\n",
    "cont_prep, _, window_labels = prep.preprocess(continuous_series=continuous_data, labels=labels)\n",
    "\n",
    "# run PBAD on the data\n",
    "mdl = PBAD(relative_minsup=0.01, jaccard_threshold=0.9, pattern_type='all', pattern_pruning='closed')\n",
    "scores = mdl.fit_predict(continuous_data=cont_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T09:57:36.912237Z",
     "start_time": "2019-04-25T09:57:36.889785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC = 0.999236874237\n"
     ]
    }
   ],
   "source": [
    "# result: we can only observe the labeled segments!\n",
    "ixl = np.where(window_labels != 0)[0]\n",
    "print('AUROC =', roc_auc_score(y_true=window_labels[ixl], y_score=scores[ixl]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T09:57:37.109218Z",
     "start_time": "2019-04-25T09:57:36.992300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running preprocessor on TIME SERIES with settings & steps:\n",
      "0. remove extreme values (mean +/- 3 * stdv) + min-max scaling is always applied FIRST\n",
      "1. scaling:             NO\n",
      "2. smoothing:           NO\n",
      "3. binning:             NO\n",
      "4. subsampling:         NO\n",
      "5. discretizing:        NO\n",
      "6. window (size - inc): 12 - 6\n",
      "\n",
      "AUROC = 0.589667277167\n"
     ]
    }
   ],
   "source": [
    "# preprocess the data\n",
    "prep = PreProcessor(scaling=False, smoothing=False, discretize=False, window_size=12, window_incr=6, bin_size=1, alphabet_size=30)\n",
    "cont_prep, _, window_labels = prep.preprocess(continuous_series=continuous_data, labels=labels)\n",
    "\n",
    "# run PAV\n",
    "mdl = PAV()\n",
    "scores = mdl.fit_predict(continuous_data=cont_prep, window_size=12, window_incr=6)\n",
    "ixl = np.where(window_labels != 0)[0]\n",
    "print('\\nAUROC =', roc_auc_score(y_true=window_labels[ixl], y_score=scores[ixl]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T09:57:42.530235Z",
     "start_time": "2019-04-25T09:57:37.173868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running preprocessor on TIME SERIES with settings & steps:\n",
      "0. remove extreme values (mean +/- 3 * stdv) + min-max scaling is always applied FIRST\n",
      "1. scaling:             NO\n",
      "2. smoothing:           NO\n",
      "3. binning:             NO\n",
      "4. subsampling:         NO\n",
      "5. discretizing:        YES\n",
      "   alphabet size:       30\n",
      "6. window (size - inc): 12 - 6\n",
      "\n",
      "DEBUG: Mining CLOSED ITEMSETS with SPMF CHARM; #rows:1211 minsup absolute: 0.01\n",
      "\n",
      "DEBUG: Found #650 patterns\n",
      "DEBUG: # Jaccard thresholded patterns: 551\n",
      "DEBUG: most frequent patterns: [(array([ 0.53]), 445), (array([ 0.5]), 428), (array([ 0.6]), 418), (array([ 0.57]), 418), (array([ 0.47]), 391)]\n",
      "DEBUG: least frequent patterns: [(array([ 0.4 ,  0.53,  0.57,  0.6 ]), 13), (array([ 0.3 ,  0.4 ,  0.47,  0.5 ,  0.53]), 13), (array([ 0.13,  0.3 ,  0.37]), 13), (array([ 0.4,  0.5,  0.6]), 13), (array([ 0.13,  0.2 ,  0.23,  0.3 ]), 13)]\n",
      "WARNING: the fpof scores are all ~0.0 or ~1.0 --> run with different preprocessing settings\n",
      "\n",
      "AUROC = 0.99503968254\n"
     ]
    }
   ],
   "source": [
    "# preprocess the data\n",
    "prep = PreProcessor(scaling=False, smoothing=False, discretize=True, window_size=12, window_incr=6, bin_size=1, alphabet_size=30)\n",
    "cont_prep, _, window_labels = prep.preprocess(continuous_series=continuous_data, labels=labels)\n",
    "\n",
    "# run FPOF\n",
    "mdl = FPOF(relative_minsup=0.01, jaccard_threshold=0.9, pattern_pruning='closed')\n",
    "scores = mdl.fit_predict(continuous_data=cont_prep)\n",
    "ixl = np.where(window_labels != 0)[0]\n",
    "print('\\nAUROC =', roc_auc_score(y_true=window_labels[ixl], y_score=scores[ixl]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix profile anomaly detection (MPAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T09:57:43.403671Z",
     "start_time": "2019-04-25T09:57:42.587176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7255/7255 [00:00<00:00, 9213.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUROC = 0.451923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess the data: matrix profile works on the original data\n",
    "prep = PreProcessor(window_size=12, window_incr=6)\n",
    "\n",
    "# run MPAD\n",
    "mdl = MPAD(window_size=12)\n",
    "scores = mdl.fit_predict(continuous_data)\n",
    "\n",
    "# transform the scores to a score per window\n",
    "w_scores = prep._fast_divide_series_into_windows(scores, 'continuous')\n",
    "scores = np.sum(w_scores, axis=1).T\n",
    "\n",
    "# compute the AUROC\n",
    "ixl = np.where(window_labels != 0)[0]\n",
    "print('\\nAUROC =', roc_auc_score(y_true=window_labels[ixl], y_score=scores[ixl]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIFPOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
